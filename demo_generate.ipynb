{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.22.1+cu128)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.9.1 (from torchvision)\n",
      "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.9.1->torchvision) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.9.1->torchvision) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.9.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.9.1->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.9.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.9.1->torchvision) (2025.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch==2.9.1->torchvision)\n",
      "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch==2.9.1->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m130.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m169.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
      "\u001b[2K  Attempting uninstall: tritonâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: triton 3.3.1[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling triton-3.3.1:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.55â”â”â”â”â”\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.55:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.55â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/18\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\u001b[0m \u001b[32m 3/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.61:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.55â”\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.55:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.55â”â”â”\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.13.0.11â”\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.13.0.11:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.13.0.11â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.57m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.57:â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.57[0m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.61[0m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.61:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.61â”â”â”â”â”\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.57[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.57:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.57â”\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu120m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.3.14â”\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.3.14:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.3.14â”â”â”\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu120m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.7.53[0m \u001b[32m11/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.7.53:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.7.53â”\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu121mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.41â”â”\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.41:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.41â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.7.1.26â”â”â”\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.7.1.26:0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.7.1.26â”â”â”â”â”\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.2.55[0m \u001b[32m14/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.2.55:m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.2.55â”\u001b[0m \u001b[32m14/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: torchâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.7.1+cu128m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.7.1+cu128:â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1+cu128[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvisionâ”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.22.1+cu128mâ”â”â”â”\u001b[0m \u001b[32m16/18\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.22.1+cu128:â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m17/18\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.22.1+cu128\u001b[90mâ”â”\u001b[0m \u001b[32m17/18\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18/18\u001b[0m [torchvision]\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 torch-2.9.1 torchvision-0.24.1 triton-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "from torchvision.io import read_image, write_jpeg\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "from src.stores import ModelProvidersFactory, DatasetProvidersFactory\n",
    "from src.utils.checkpoints_utils import load_checkpoint\n",
    "from src.Preprocessing.volleyball_annot_loader import load_tracking_annot\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Constants / Dictionaries\n",
    "# =========================\n",
    "CATEGORIES_DICT = {\n",
    "    'l-pass': 0,\n",
    "    'r-pass': 1,\n",
    "    'l-spike': 2,\n",
    "    'r_spike': 3,\n",
    "    'l_set': 4,\n",
    "    'r_set': 5,\n",
    "    'l_winpoint': 6,\n",
    "    'r_winpoint': 7\n",
    "}\n",
    "\n",
    "ACTIONS_DICT = {\n",
    "    \"waiting\": 0,\n",
    "    \"setting\": 1,\n",
    "    \"digging\": 2,\n",
    "    \"falling\": 3,\n",
    "    \"spiking\": 4,\n",
    "    \"blocking\": 5,\n",
    "    \"jumping\": 6,\n",
    "    \"moving\": 7,\n",
    "    \"standing\": 8\n",
    "}\n",
    "\n",
    "ID_TO_CATEGORY = {v: k for k, v in CATEGORIES_DICT.items()}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Paths\n",
    "# =========================\n",
    "VIDEO_ROOT = \"data/volleyball/volleyball_/videos/4\"\n",
    "TRACK_ROOT = \"data/volleyball/volleyball_tracking_annotation/volleyball_tracking_annotation/4\"\n",
    "GROUP_GT_PATH = \"data/volleyball/volleyball_/videos/4/annotations.txt\"\n",
    "SAVE_ROOT = \"./demo/4\"\n",
    "\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Load group GT annotations\n",
    "# =========================\n",
    "from src.Preprocessing.boxinfo import BoxInfo\n",
    "def load_group_annotations(path):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        { clip_name (str) : group_label_id (int) }\n",
    "    \"\"\"\n",
    "    clip_gt = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            clip_name = parts[0].replace(\".jpg\", \"\")\n",
    "            group_label = parts[1]\n",
    "            clip_gt[clip_name] = CATEGORIES_DICT[group_label]\n",
    "    return clip_gt\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load tracking annotations\n",
    "# (your exact logic preserved)\n",
    "# =========================\n",
    "def load_tracking_annot(path):\n",
    "    with open(path, 'r') as file:\n",
    "        player_boxes = {idx: [] for idx in range(12)}\n",
    "        frame_boxes_dct = {}\n",
    "\n",
    "        for line in file:\n",
    "            box_info = BoxInfo(line)\n",
    "            if box_info.player_ID > 11:\n",
    "                continue\n",
    "            player_boxes[box_info.player_ID].append(box_info)\n",
    "\n",
    "        # build frame â†’ boxes view\n",
    "        for player_ID, boxes_info in player_boxes.items():\n",
    "            # keep middle frames only (as in your code)\n",
    "            boxes_info = boxes_info[5:]\n",
    "            boxes_info = boxes_info[:-6]\n",
    "\n",
    "            for box_info in boxes_info:\n",
    "                if box_info.frame_ID not in frame_boxes_dct:\n",
    "                    frame_boxes_dct[box_info.frame_ID] = []\n",
    "                frame_boxes_dct[box_info.frame_ID].append(box_info)\n",
    "\n",
    "        return frame_boxes_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-27 22:57:01] - [FeaturesDataset.py:54] - [INFO]: Initializing Features Dataset...\n",
      "[2025-12-27 22:57:01] - [FeaturesDataset.py:74] - [INFO]: Collecting Images' features and labels...\n",
      "[2025-12-27 22:57:01] - [FeaturesDataset.py:56] - [INFO]: Features Dataset Initialized with 153 Samples!\n",
      "[2025-12-27 22:57:01] - [FeaturesDataset.py:54] - [INFO]: Initializing Features Dataset...\n",
      "[2025-12-27 22:57:01] - [FeaturesDataset.py:74] - [INFO]: Collecting Images' features and labels...\n",
      "[2025-12-27 22:57:01] - [FeaturesDataset.py:56] - [INFO]: Features Dataset Initialized with 100 Samples!\n",
      "[2025-12-27 22:57:01] - [baseline8.py:61] - [INFO]: Initializing Two Stage Activity Temporal Classifier...\n",
      "[2025-12-27 22:57:01] - [baseline8.py:85] - [INFO]: Model Initialized Successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Two_Stage_Pooled_Teams_Activity_Temporal_Classifier(\n",
       "  (player_lstm): LSTM(2048, 1024, batch_first=True)\n",
       "  (adaptive_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (frame_lstm): LSTM(2048, 512, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Device\n",
    "# =========================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load GT\n",
    "# =========================\n",
    "group_gt = load_group_annotations(GROUP_GT_PATH)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Create dataloader (for consistency with training)\n",
    "# =========================\n",
    "dataset_factory = DatasetProvidersFactory()\n",
    "\n",
    "_, testloader = dataset_factory.get_data_loaders(\n",
    "    4,\n",
    "    \"data/volleyball/volleyball_/videos\",\n",
    "    \"data/volleyball/volleyball_tracking_annotation/volleyball_tracking_annotation\",\n",
    "    [0],\n",
    "    [4],\n",
    "    True,\n",
    "    \"logs/baselines_logs/baseline8_logs\",\n",
    "    CATEGORIES_DICT,\n",
    "    \"output/player_level_features\",\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    True\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Create model (MATCH TRAINING CONFIG)\n",
    "# =========================\n",
    "models_factory = ModelProvidersFactory()\n",
    "\n",
    "model = models_factory.create(\n",
    "    model_name=\"b8\",\n",
    "    num_classes=8,\n",
    "    input_size=2048,     # ðŸ”¥ MUST match checkpoint\n",
    "    hidden_size1=1024,\n",
    "    hidden_size2=512,\n",
    "    num_layers=1,\n",
    "    log_dir=\"logs/baselines_logs/baseline8_logs\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"models/b8/best_model.pth\", map_location=\"cpu\")\n",
    "model = load_checkpoint(checkpoint=checkpoint, model=model)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] clip=105655, frames=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26574/2423073228.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.float32).to(device)\n",
      "/tmp/ipykernel_26574/2423073228.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long).to(device)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/utils.py:233: UserWarning: Argument 'font_size' will be ignored since 'font' is not set.\n",
      "  warnings.warn(\"Argument 'font_size' will be ignored since 'font' is not set.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] clip=105735, frames=9\n",
      "[DEBUG] clip=105755, frames=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] clip=105805, frames=9\n",
      "[DEBUG] clip=105860, frames=9\n",
      "[DEBUG] clip=105865, frames=9\n",
      "[DEBUG] clip=105890, frames=9\n",
      "[DEBUG] clip=105930, frames=9\n",
      "[DEBUG] clip=105950, frames=9\n",
      "[DEBUG] clip=105970, frames=9\n",
      "[DEBUG] clip=106040, frames=9\n",
      "[DEBUG] clip=106095, frames=9\n",
      "[DEBUG] clip=106135, frames=9\n",
      "[DEBUG] clip=106145, frames=9\n",
      "[DEBUG] clip=115100, frames=9\n",
      "[DEBUG] clip=115155, frames=9\n",
      "[DEBUG] clip=115200, frames=9\n",
      "[DEBUG] clip=115220, frames=9\n",
      "[DEBUG] clip=115270, frames=9\n",
      "[DEBUG] clip=115305, frames=9\n",
      "[DEBUG] clip=115330, frames=9\n",
      "[DEBUG] clip=115365, frames=9\n",
      "[DEBUG] clip=130405, frames=9\n",
      "[DEBUG] clip=130430, frames=9\n",
      "[DEBUG] clip=130505, frames=9\n",
      "[DEBUG] clip=130545, frames=9\n",
      "[DEBUG] clip=130585, frames=9\n",
      "[DEBUG] clip=130630, frames=9\n",
      "[DEBUG] clip=130670, frames=9\n",
      "[DEBUG] clip=133335, frames=9\n",
      "[DEBUG] clip=133370, frames=9\n",
      "[DEBUG] clip=133390, frames=9\n",
      "[DEBUG] clip=133475, frames=9\n",
      "[DEBUG] clip=133525, frames=9\n",
      "[DEBUG] clip=133555, frames=9\n",
      "[DEBUG] clip=133595, frames=9\n",
      "[DEBUG] clip=133655, frames=9\n",
      "[DEBUG] clip=133675, frames=9\n",
      "[DEBUG] clip=133740, frames=9\n",
      "[DEBUG] clip=133765, frames=9\n",
      "[DEBUG] clip=133805, frames=9\n",
      "[DEBUG] clip=138185, frames=9\n",
      "[DEBUG] clip=24635, frames=9\n",
      "[DEBUG] clip=24665, frames=9\n",
      "[DEBUG] clip=24690, frames=9\n",
      "[DEBUG] clip=24695, frames=9\n",
      "[DEBUG] clip=24715, frames=9\n",
      "[DEBUG] clip=24745, frames=9\n",
      "[DEBUG] clip=24790, frames=9\n",
      "[DEBUG] clip=24805, frames=9\n",
      "[DEBUG] clip=24855, frames=9\n",
      "[DEBUG] clip=24885, frames=9\n",
      "[DEBUG] clip=24900, frames=9\n",
      "[DEBUG] clip=24940, frames=9\n",
      "[DEBUG] clip=24975, frames=9\n",
      "[DEBUG] clip=25000, frames=9\n",
      "[DEBUG] clip=30985, frames=9\n",
      "[DEBUG] clip=31010, frames=9\n",
      "[DEBUG] clip=31055, frames=9\n",
      "[DEBUG] clip=31095, frames=9\n",
      "[DEBUG] clip=31130, frames=9\n",
      "[DEBUG] clip=31170, frames=9\n",
      "[DEBUG] clip=31920, frames=9\n",
      "[DEBUG] clip=33825, frames=9\n",
      "[DEBUG] clip=34395, frames=9\n",
      "[DEBUG] clip=35580, frames=9\n",
      "[DEBUG] clip=37245, frames=9\n",
      "[DEBUG] clip=37920, frames=9\n",
      "[DEBUG] clip=39330, frames=9\n",
      "[DEBUG] clip=41445, frames=9\n",
      "[DEBUG] clip=43005, frames=9\n",
      "[DEBUG] clip=43635, frames=9\n",
      "[DEBUG] clip=44265, frames=9\n",
      "[DEBUG] clip=44805, frames=9\n",
      "[DEBUG] clip=48890, frames=9\n",
      "[DEBUG] clip=48930, frames=9\n",
      "[DEBUG] clip=48960, frames=9\n",
      "[DEBUG] clip=48980, frames=9\n",
      "[DEBUG] clip=49080, frames=9\n",
      "[DEBUG] clip=49115, frames=9\n",
      "[DEBUG] clip=49140, frames=9\n",
      "[DEBUG] clip=64375, frames=9\n",
      "[DEBUG] clip=64410, frames=9\n",
      "[DEBUG] clip=64420, frames=9\n",
      "[DEBUG] clip=64490, frames=9\n",
      "[DEBUG] clip=64570, frames=9\n",
      "[DEBUG] clip=64610, frames=9\n",
      "[DEBUG] clip=64635, frames=9\n",
      "[DEBUG] clip=89180, frames=9\n",
      "[DEBUG] clip=89220, frames=9\n",
      "[DEBUG] clip=89245, frames=9\n",
      "[DEBUG] clip=89265, frames=9\n",
      "[DEBUG] clip=89315, frames=9\n",
      "[DEBUG] clip=89340, frames=9\n",
      "[DEBUG] clip=91480, frames=9\n",
      "[DEBUG] clip=91510, frames=9\n",
      "[DEBUG] clip=91520, frames=9\n",
      "[DEBUG] clip=91545, frames=9\n",
      "[DEBUG] clip=91590, frames=9\n",
      "[DEBUG] clip=91620, frames=9\n",
      "[DEBUG] clip=91655, frames=9\n",
      "[DEBUG] clip=91685, frames=9\n",
      "[DEBUG] clip=91710, frames=9\n",
      "[DEBUG] clip=94340, frames=9\n",
      "[DEBUG] clip=94365, frames=9\n",
      "[DEBUG] clip=94375, frames=9\n",
      "[DEBUG] clip=94420, frames=9\n",
      "[DEBUG] clip=94450, frames=9\n",
      "[DEBUG] clip=94470, frames=9\n",
      "[DEBUG] clip=94510, frames=9\n",
      "[DEBUG] clip=94540, frames=9\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Visualization + inference\n",
    "# =========================\n",
    "from PIL import ImageFont\n",
    "\n",
    "for clip in sorted(os.listdir(VIDEO_ROOT)):\n",
    "    clip_path = os.path.join(VIDEO_ROOT, clip)\n",
    "    track_file = os.path.join(TRACK_ROOT, clip, f\"{clip}.txt\")\n",
    "\n",
    "    if not os.path.exists(track_file):\n",
    "        continue\n",
    "\n",
    "    frames_ann = load_tracking_annot(track_file)\n",
    "    print(f\"[DEBUG] clip={clip}, frames={len(frames_ann)}\")\n",
    "\n",
    "    save_clip = os.path.join(SAVE_ROOT, clip)\n",
    "    os.makedirs(save_clip, exist_ok=True)\n",
    "\n",
    "    # ---- group prediction (clip-level) ----\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "\n",
    "            if isinstance(data, list):\n",
    "                data, target = np.array(data), np.array(target)\n",
    "\n",
    "            data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "            target = torch.tensor(target, dtype=torch.long).to(device)\n",
    "\n",
    "            # Forward\n",
    "            logits = model(data)\n",
    "\n",
    "            # Predictions\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    pred_group = preds[0]\n",
    "\n",
    "    gt_group = group_gt[clip]\n",
    "\n",
    "    pred_group_int = int(pred_group.cpu())  # <-- convert to int\n",
    "    gt_group_int = int(gt_group)            # if gt_group is not already int\n",
    "\n",
    "\n",
    "    # ---- frame-level drawing ----\n",
    "    for frame_id, players in frames_ann.items():\n",
    "        img_path = os.path.join(clip_path, f\"{frame_id}.jpg\")\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "\n",
    "        img = read_image(img_path)\n",
    "\n",
    "        boxes, labels = [], []\n",
    "        for box_info in players:\n",
    "            x1, y1, x2, y2 = box_info.box\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            labels.append(box_info.category)  # âœ… GT player label only\n",
    "\n",
    "        # draw players\n",
    "        if len(boxes) > 0:\n",
    "            img = draw_bounding_boxes(\n",
    "                image=img,\n",
    "                boxes=torch.tensor(boxes),\n",
    "                labels=labels,\n",
    "                colors=\"#FF00FF\",\n",
    "                width=3,\n",
    "                font_size=30\n",
    "            )\n",
    "\n",
    "        # draw group GT vs prediction\n",
    "        colors = [\"#00FF00\", \"#00FF00\" if gt_group == pred_group else \"#FF0000\"]\n",
    "        \n",
    "        img = draw_bounding_boxes(\n",
    "            image=img,\n",
    "            boxes=torch.tensor([\n",
    "                [250, 0, 600, 50],\n",
    "                [600, 0, 850, 50]\n",
    "            ]),\n",
    "            labels=[\n",
    "                f\"ground_truth: {ID_TO_CATEGORY[gt_group_int]}\",\n",
    "                f\"predicted: {ID_TO_CATEGORY[pred_group_int]}\"\n",
    "            ],\n",
    "            colors=colors,\n",
    "            width=0,\n",
    "            font_size=60\n",
    "        )\n",
    "\n",
    "        write_jpeg(img, os.path.join(save_clip, f\"{frame_id}.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
